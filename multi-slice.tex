\vspace{-0.1cm}\section{Thrust 1: Volumetric reconstruction for 3D aberration correction}\vspace{-0.1cm}

%\input{fig_multi_slice}
\input{fig_DOTWFS_setup}
\subsection{Imaging setup}
\figref{fig:dot-wfs} illustrates our imaging system, with separate views highlighting the components for  diffraction tomography  reconstruction and for fluorescence imaging with wavefront shaping (WFS) correction.

The first stage, depicted in \figref{fig:dot-wfs}(a), involves the refractive index (RI) reconstruction. A coherent plane wave illuminates the tissue from the far side, namely, in transmission mode. A camera captures the resulting complex wavefront after it has been scattered by the tissue. A galvo mirror  tilts the incident illumination, recording  scattered patterns  under different illumination angles. An optimization algorithm   is then employed to reconstruct the 3D RI volume that best explains the ensemble of measured scattering patterns.

Next, the setup transitions to the fluorescence imaging mode illustrated in \figref{fig:dot-wfs}(b). The recovered 3D RI volume is used to computationally determine the WFS modulation patterns required to compensate for the aberration at any point within the tissue. For the excitation path, laser light is introduced from the front, passing through the SLM. The modulation displayed on the SLM is designed to display the conjugate phase of the tissue aberration, such that the wavefront is pre-compensated and focuses coherently to the desired  spot inside the tissue volume. The resultant fluorescent emission is then collected by the front-side camera. The emitted light is also aberrated by the tissue structure. The SLM is used to apply a reciprocal correction to the detection path, ensuring that light emerging from the target spot is coherently collected onto a single sensor pixel. \figref{fig:dot-wfs}(b) conceptually validates this correction: without modulation, the camera observes only a wide, noisy blob of scattered light; with the correction, a sharp spot is recovered.  To visualize the focusing inside the tissue we illustrate here a target spot at the back of the tissue layer and not in the middle of the volume, therefore a validation camera behind the tissue can observe an aberration free image of it. If we illuminate the tissue from the front without any correction  the incoming light is scattered and illuminates a wide area around the desired point. But with an aberration correction on the SLM the light is focused and only excites the desired point.
To image the full 3D volume using this basic system, we  perform a confocal scan, where we sequentially display dedicated modulation patterns on the SLM to focus the light at each point of the volume. This scanning will be relaxed in trust 2.  





\subsection{Thrust 1.1: Diffraction Tomography-Informed Wavefront Shaping}
\boldstart{Parametric model for 3D aberration correction.}
The primary challenge in correcting aberrations within a 3D tissue is that the scattering process occurs throughout the volume, resulting in a unique, accumulated phase distortion for light propagating to or from every distinct spatial point. To accurately predict this complex aberration, we require a  3D model of the tissue's  RI distribution.

Formally, the RI volume can be recovered by solving the wave equation.
 However, computing an exact solution to the wave equation—for example, using finite-difference time-domain (FDTD) methods \cite{FDTDYee66,mudiff,kWaves}—is computationally prohibitive for realistic  volumes. Instead, we employ a multi-slice model \cite{Kamilov:15,Chowdhury:19,Chen:20}. This model approximates the volume by a series of planar aberration screens, separated by a small axial distance $\eps$, with free-space propagation assumed between successive layers. %Since propagation is efficiently calculated via FFT methods, this provides a relatively fast 3D computation of the light's forward scattering, which is a fairly accurate representation for biological tissue that typically exhibits minimal back-scattering.

We denote $\refin(x,y,z)$ as the difference between the RI at  3D point $\ptd$ and the RI of the surrounding medium. We use $M$ layers to approximate a volume of thickness $d=\eps M$. The 2D aberration of the $m$-th layer, at depth $z=m\eps$, is denoted by $\AbrVect_m(x,y)$, which corresponds to the  RI variations: \BE\label{eq:abr-to-vol} \AbrVect_m(x,y)=e^{\frac{2\pi i \eps}{\lambda}\refin(x,y,m\eps)}. \EE

We denote an incoming plane wave illumination from direction $\omgv$ as $\bu_\omgv$.
%, where: \BE \bu_\omgv(x,y)=e^{\frac{2\pi i}{\lambda}(\omgv_x\cdot x+\omgv_y\cdot y)}. \EE 
The resulting wavefront scattered to the camera, $\bt_\omgv$, is related to the incident field $\bu_\omgv$ by a linear Transmission Matrix ($\TM$), such that $\bt_\omgv=\TM\bu_\omgv$. In the multi-slice model, the $\TM$ is defined by the $M$ planar aberration layers: \BE\label{eq:multi-layer-transmission-matrix} \TM=\OpPr_{O} \DiagM(\AbrVect_M) \ldots \OpPr_\eps \DiagM(\AbrVect_{1}) \OpPr_\eps, \EE where $\DiagM(\AbrVect_m)$ is a diagonal matrix performing element-wise multiplication of the incoming wavefront by the aberration. $\OpPr_\eps$ is a convolution matrix describing free-space propagation over the distance $\eps$. $\OpPr_{O}$ accounts for the final  propagation from the tissue boundary, through the optics, to the camera sensor. The propagation operators $\OpPr_\eps$ and $\OpPr_{O}$ are independent of the tissue structure and are assumed known (or calibrated). If we discretize the incoming and outgoing wavefronts using $N\times N$ entries, the matrix $\TM$ involves $N^4$ variables. The multi-slice model offers significant compression, describing the matrix using only $N^2\cdot M$ variables, where typically $M\ll N^2$.

The multi-slice model also allows us to express the wavefront $\bt_\ptd$ emitted from a 3D point $\ptd=(\ptd^x,\ptd^y,\ptd^z)$ inside the volume. We represent this point by an indicating vector $\be_{\ptd}$, which is a 2D array with a single non-zero entry corresponding to the point's lateral ($\ptd^x,\ptd^y$) position. We denoting by $m(\ptd)$ the index  of the closest  aberration layer  $m(\ptd) =\left\lceil\frac{\ptd^z}{\eps}\right\rceil. $
%$m(\ptd)$: \BE m(\ptd)=\left\lceil\frac{\ptd^z}{\eps}\right\rceil. \EE
 The resulting wavefront $\bt_\ptd$ is calculated by propagating the light through the layers between the emission point and the camera: \BE\label{eq:multi-layer-abrr-point} \bt_\ptd=\OpPr_{O} \DiagM(\AbrVect_M) \ldots \OpPr_\eps \DiagM(\AbrVect_{m(\ptd)+1}) \OpPr_\eps \DiagM(\AbrVect_m(\ptd))\OpPr_{m(\ptd)\eps-\ptd^z}\be_\ptd. \EE



\boldstart{Diffraction tomography reconstruction.}
In diffraction tomography, we measure a set of input-output pairs $(\bu_\omgv,\bt_\omgv)$. The objective is to solve an optimization problem that seeks the set of aberration layers $\AbrVect_1,\ldots\AbrVect_M$ that best fit the measured data: \BE\label{eq:multi-slice-T-mat-fit} \min_{\AbrVect_1,\ldots\AbrVect_M}\sum_{j}\left|{\bt_{\omgv_j}}^{\text{measured}}-{\bt_{\omgv_j}}(\AbrVect_1,\ldots\AbrVect_M)\right|^2, \EE where ${\bt_{\omgv_j}}^{\text{measured}}$ is the measured wavefront, and ${\bt_{\omgv_j}}(\AbrVect_1,\ldots\AbrVect_M)$ is the forward model from \equref{eq:multi-layer-transmission-matrix}, which is dependent on the aberration layers. This fitting error is minimized using  gradient descent optimization. The propagation steps between layers are implemented efficiently using Fourier domain convolution. Some prior reconstructions from our lab are illustrated in \figref{fig:odtres}.
When the tissue aberration is weak, the model can be  linearized using the First-Born approximation \cite{Devaney:81,Lin:92,Chen:98,Nguyen2017,PMID:17694065}. This allows the inversion problem to be solved   in closed-form, thereby significantly accelerating reconstruction \cite{WOLF1969153,CotteNatPhot2013}.

\boldstart{Fluorescence imaging and sectioning strategy.}
Given a volumetric reconstruction of the tissue's refractive index from the diffraction tomography stage, we can proceed to image the fluorescent components. For a single-SLM, point-scanning system, we sequentially excite every 3D point $\ptd$ by displaying a dedicated SLM modulation pattern that corresponds to the conjugate of the scattered wavefront $\bt_\ptd$, computed using \equref{eq:multi-layer-abrr-point}.

We plan to exploit a single-photon (1P) excitation approach. %1P excitation is simpler and less costly, utilizes visible light, and requires lower power, minimizing potential photo-damage to sensitive biological tissue. 
To achieve the necessary depth sectioning and prevent mixing of signals from different depths, we will employ a confocal gating strategy by correcting both the excitation and emission wavefronts, similar to our previous work \cite{DrorNatureComm24}. Specifically, we correct the incoming path to maximize power focused at the desired excitation point $\ptd$. Simultaneously, we correct the emitted light to undo the scattering effects, ensuring all photons emerging from $\ptd$ are refocused by the SLM onto a single sensor pixel. The confocal measurement isolates the signal from the central pixel; because the emitted wavefront is corrected, this gating step does not discard a significant number of photons, thereby preserving the SNR. Since the spectral gap between the 1P excitation and emission is typically small, we have previously used the same SLM modulation to correct both the excitation and emission arms \cite{DrorNatureComm24}.

In this research, we will primarily exploit the 1P approach due to its simplicity and reduced photo-toxicity. While two-photon (2P) excitation offers superior penetration, inherent depth sectioning and background rejection, its high cost, complex assembly, and need for significantly higher excitation power (which poses a greater risk to sensitive embryos) place it beyond the current scope. 2P scanning with WFS correction remains a valuable and important future direction to explore upon successful demonstration of the 1P correction system.

%\boldstart{Recoverable information for diffraction tomography.}
%Ideally, the aberration layers estimated by the diffraction tomography process should fully recover the 3D RI of the tissue, as expressed in \equref{eq:abr-to-vol}. In practice, however, the reconstruction suffers from limited axial resolution due to the missing cone problem \cite{WOLF1969153,mertz2019introduction,Lauer2002,MertzBook}. This limitation arises because the finite numerical aperture (NA) of the objective restricts the measurable range of lateral frequencies. While the missing cone is a fundamental constraint of the diffraction tomography framework, our recent research \cite{levin2024TM} has demonstrated that it does not compromise the performance of the WFS correction. Since the correction itself is fundamentally restricted to the same finite objective NA, the spatial frequencies that cannot be measured are precisely the frequencies that are not needed for computing the correct compensating wavefront.
%





%\boldstart{Flourescent imaging:}
%Given a volumetric reconstruction output from the diffraction tomography stage, we want to scan the volume and sequentially excite every 3D point $\ptd$, while placing on the SLM a modulation dedicated to that position,  corresponding to the conjugate of $\bt_\ptd$ computed using \equref{eq:multi-layer-abrr-point}.  
%
%Here we have the choice between single-photon (1P) and two-photon (2P) excitation. 
%Single-photon is a simpler and cheaper process, as the excitation is done using visible wavelength light, and the power required is much lower, resulting in less damage to the tissue. To image with 1P we need to use confocal gating to get depth sectioning, so that points at different depths do not mix. For that we plan to use a setup similar to our previous work~\cite{DrorNatureComm24} where both excitation and emission wavefronts are corrected. That is, we attempt to correct the incoming path so that scattering is minimized and most incoming power focus at the desired point  $\ptd$ inside the tissue. We also correct the emitted light to undo the scattering of the emitted light, so that all the photons emerging from a single 3D point $\ptd$   are redirected by the SLM to a single spo on the sensor. The confocal  measurement uses  only the light which gets into the central pixel of the sensor, but since the emitted  wavefront is corrected on its way to the sensor,  the confocal gating (taking only light at the center of the sensor) does not discard a lot of photons. 
% Since the wavelength gap between the excitation and emission is very small we previously noticed~\cite{DrorNatureComm24} that we can correct both arms using the same SLM modulation. 
%
%With 2P excitation one excites with a longer wavelength which is less susceptible to tissue aberration. Also as emission power is a non-linear function of excitation, depth sectioning is obtained without the need for confocal gating, and all the emitted photons are collected by a single wide detector. The disadvantage is that the system is costly and complicated to assemble, and more critically, much more excitation power is required, which can be harmful to sensitive embryo tissue.
%
%In this research we plan to exploit the 1P approach since it is a simpler process which is less harmful to the tissue. 2P scanning with wavefront shaping correction is a valuable future direction we will explore upon a successful demonstration of a 1P correction, but may exceed the scope of this project.
%At a third stage, our approach can allow the usage of 2P  excitation, where we correct both the excitation and emission arms. This would provide even better background rejection, and can allow to further improve the penetration depth. 


%Ideally, the aberration layers estimated  by a   diffraction tomography  process should recover the 3D refractive index of the tissue as expressed in \equref{eq:abr-to-vol}.
%In practice the reconstruction is never exact. To understand what can be reconstructed it is common to use the linearized first-Born approximation. Under this model $\frefin(\bkv)$, the 3D Fourier transform of the refractive volume $\refin(\ptd)$ is analyzed.
% Classical results in optics show~\cite{WOLF1969153,mertz2019introduction,Lauer2002,MertzBook} that if the range of illumination wavefronts we can use is bounded by the numerical aperture $\NA$ of the illumination objective and if the outgoing scattered wavefronts are also measured using an objective with a similar aperture extent,  the propagating wavefronts only measure a subset of frequencies from the spectrum $\frefin(\bkv)$, bounded by a butterfly shape illustrated in \figref{} and defined mathematically as
%\BE\label{eq:butterfly-shape}
%{\small|\zkv|\leq \NA \xykvnor -\frac{\lambda}{2}\xykvnor^2, \quad {\text{with}}\quad \xykvnor=\sqrt{\xkv^2+\ykv^2}.}
%\EE
%This is also known as the missing cone problem~\cite{MertzBook}, a large cone of frequencies cannot be measured, which limits the axial resolution of diffraction tomography reconstruction.
%While this is considered as one of the limitations of the diffraction tomography framework, the missing cone is not a problem for wavefront shaping corrections since the correction is limited by the same aperture stop and the missing frequencies are not needed for computing the correction. 
%
%The missing cone is derived using a linearized model. In practice when the tissue is thick light scattered more then once on its way through the volume and hence some of the content in the missing cone region is included in the multiple scattering paths. However, multiple scattering information is non-linear and non convex, so the optimization may not succeed in extracting it.  

%In a similar way, if can be shown~\cite{} that by the linear weakly scattering  model, a reflection mode microscope only measures information at the higher canopy of the 3D spectrum, illustrated in \figref{}.  An OCT filtering can somewhat extend this range, depending on its depth sectioning resolution, but still only the high frequencies are measured. At the same time the frequencies needed for the wavefront shaping correction are the low frequencies inside the butter-fly shape of \figref{}. 
%However, in a reflection mode microscope the low frequencies are only accessible via the multiple scattering paths. This makes their extraction non linear and noise sensitive.  This argument explains why our application, where access to both sides of the target is possible, is free from many of the limitations   of current wavefront shaping systems and needs to tackle a significantly simpler optimization. 

\subsection{Trust 1.2: Exploiting NIR Wavelengths to Extend Penetration Depth}
To mitigate project risk, we will initially use the exact wavelengths required for single-photon excitation as input for the diffraction tomography stage. Success in this initial task will already provide a significant improvement in penetration depth compared to standard wide-field microscopy. At the second stage, we plan to further enhance imaging depth by incorporating Near-Infrared (NIR) illumination.

The diffraction tomography problem attempts to solve a non-linear and non-convex optimization task. While this yields satisfactory results for samples of moderate optical thickness, the problem becomes highly non-convex as optical thickness increases due to multiple scattering events, often preventing the optimization from converging to the global minimum.  

To enable imaging of thicker targets, we plan to exploit longer NIR wavelengths. Tissue scattering is highly wavelength-dependent, and prior measurements consistently report a significant reduction in scattering as the illumination wavelength increases \cite{Cheong90,tuchin2007tissue,CAVE_0282,Jacques2013,Sandell2011,BASHKATOV2011,TDurduran_2002}. Consequently, the diffraction tomography optimization problem is simplified at longer wavelengths, suffering from fewer local minima. For targets of medium optical thickness, the NIR scattering may be sufficiently weak to permit the use of the linearized First-Born approximation \cite{Devaney:81,Lin:92,Chen:98,Nguyen2017,PMID:17694065,WOLF1969153,CotteNatPhot2013}, leading to  efficient, closed-form reconstruction.



\boldstart{Converting solutions at different wavelengths.}
Although the optimization is solved robustly at the longer NIR wavelength ($\lambnir$), our final correction requires the shorter, visible wavelength ($\lambvis$) necessary to excite most fluorophores. To convert the $\lambnir$ reconstruction into a $\lambvis$ correction, we rely on the relationship of \equref{eq:abr-to-vol}, which relates the phase of the aberration mask to the RI volume. The aberration layers $\AbrVect^{\lambnir}_1(x,y),\ldots,\AbrVect^{\lambnir}_M(x,y)$
 computed at $\lambnir$ can be converted to the required aberration layers at $\lambvis$ simply by scaling their phase by the wavelength ratio $\lambnir/\lambvis$. Using this scaled mask, the modulations $\bt_\ptd$ are then recomputed using \equref{eq:multi-layer-abrr-point}, with the propagation operators $\OpPr_\eps$ and $\OpPr_{O}$ adjusted for $\lambvis$. This is very different than just scaling the phase of the final wavefronts $\bt_\ptd$  by $\lambnir/\lambvis$. The phase of  $\bt_\ptd$ undergoes complex and rapid $2\pi$  wraps, whereas the RI variations in the volume layers ($\AbrVect_m$) are much smoother and contain lower phase variations.

We acknowledge that the long-wavelength reconstruction only provides a low-resolution estimate of the volume, and short-wavelength propagation involves higher spatial frequencies. However, since the volumetric structure of most biological tissues is piecewise smooth, the essential information for aberration correction is largely contained within these low frequencies. As confirmed by our numerical simulations (see below), a low-resolution volume reconstruction provides sufficiently useful information for WFS correction even when applied to the shorter, visible wavelength.


\boldstart{Multi-scale diffraction tomography.}
A potential concern associated with the wavelength conversion is errors introduced by chromatic dispersion—the variation of the tissue's RI with wavelength. However, prior studies~\cite{tuchin2007tissue,Deng2015,Papadopoulos2021} indicate that the RI variation in tissue over the relevant spectral range is typically very low (e.g., the RI of water changes by only $\sim2\%$ between $400nm$ and $1200nm$). The dramatic difference in speckle patterns observed when illuminating the same tissue at two different wavelengths is primarily a result of the difference in the propagation operators ($\OpPr_\eps$), not material dispersion. Our model inherently accounts for these wavelength-dependent propagation operators.
To mitigate the influence of chromatic dispersion and to incorporate the high spatial frequencies missing from the long-wavelength reconstruction, we propose a multi-scale diffraction tomography approach. We will measure light propagation using both NIR (long) and Vis (short) wavelengths on the same tissue volume. The optimization begins with the  NIR measurement. The resulting low-resolution NIR reconstruction is then used as a powerful, low-resolution initialization for a second optimization step that utilizes the high-resolution visible measurements. As our simulations demonstrate, solving the $\lambvis$ problem directly often converges to undesired local minima in multiply scattering volumes. The low resolution initialization helps the  $\lambvis$ optimization escape these minima and efficiently converge to the high-resolution solution, while simultaneously refining the small RI deviations between the two wavelengths. This approach is analogous to multi-scale methods in geophysical imaging, where a robust, low-resolution model from long-wavelength data acts as a prior to regularize the non-convex reconstruction of the high-resolution, short-wavelength data \cite{Bunks1995, Sirgue2004}.


\input{fig_multiwavelengthWFS}

%The possible concern is that the butterfly shape is a function of wavelength, and the butterfly recovered by a long wavelength is magnificently smaller than the short-wavelength butterfly needed for computing the short wavelength modulation. This implies that the corrections we will be able to compute from the long wavelength reconstruction are only an approximation of the desired correction patterns. In practice, as we illustrate below this approximation is quite effective in correcting the aberration. 
%To understand this we note in \figref{} that the two butterflies have the same shape around the origin and differ only at the high frequencies. 
%On the other hand, $\refin(\ptd)$ is the structure of a tissue which is usually piecewise smooth, hence most of the energy of the spectrum $\frefin(\bkv)$ is usually concentrated at the low frequencies. Therefore the high frequencies we miss from the short-wavelength butterfly anyway contain limited power. We illustrate this in \figref{}.


%
%Even if the diffraction tomography uses NIR wavelengths, most fluorescent markers of interest are designed for visible wavelengths. To excite them using NIR wavelengths we will need to use 2-photon excitation which requires very high dose of energy, some research reports $10^4\times $ more power~\cite{}. This high power is harmful to the tissue. Ideally our goal is to image with a single photon excitation which requires much lower power. 
%Since the process is linear, to achieve depth sectioning we need to use a confocal correction of both the incoming and outgoing light.
%


\boldstart{Numerical Simulation:} We validated the multi-scale diffraction tomography  approach numerical, using a 3D  phantom composed of spherical particles embedded in a medium with a differing RI, as visualized in \figref{fig:multi-wavelength-numerical-sim}. Light propagation was simulated through this volume at two  wavelengths: a long wavelength, $\lambnir=1200nm$, and a short wavelength, $\lambvis=400nm$. We analyzed two scenarios of volume density.

For the low-density volume, the optimization for $\lambvis$ successfully converges, demonstrating the basic feasibility of the short-wavelength diffraction-tomography approach. However, for the denser volume scattering is significantly stronger, the direct optimization of the $\lambvis$ data becomes highly non-convex and diverges due to  local minima. In contrast, the $\lambnir$ reconstruction encounters less scattering and converges successfully.
%, demonstrating a simpler optimization landscape at longer wavelengths.
 We then utilize this converged $\lambnir$ reconstruction as a low-resolution initialization for the $\lambvis$ inversion process, which successfully guides the optimization to the desired solution.

To quantitatively evaluate the efficacy of the recovered RI models, we use them to compute the necessary WFS phase modulations at the short wavelength $\lambvis$. These modulations are designed to focus light to a target plane in the middle of the tissue, computed using \equref{eq:multi-layer-abrr-point}. We then back-propagate these computed wavefronts through the ground truth volume structure to assess the quality of the resulting focus. The wavefront reaching the target plane is visualized in \figref{fig:multi-wavelength-numerical-sim}.
To improve visualization, each  image is normalized to its own maxima and the actual maximum intensity before normalization is denoted above it. A perfect wavefront shaping modulation would reach an energy of $1$, so lower values imply the correction is not exact.
 The simulation results show the following: For the dense volume, applying no modulation results in a highly scattered pattern with virtually no spot formation. However, the $\lambnir$ reconstruction (despite its low resolution) already enables the formation of a well-focused spot, delivering  $50\%$ of the available energy. When this low-resolution $\lambnir$  result is used to initialize the $\lambvis$  optimization, the energy delivery is further improved, validating our multi-scale approach for tackling highly scattering regimes.



 
%\boldstart{Additional regularization strategies.} The above simulation demonstrates feasibility using simple $L_2$ regularization. As part of the project, we plan to explore smarter regularizations strategies.
%In particular, recent diffraction-tomography approaches~\cite{Zhou:20,liu2022recoverycontinuous3drefractive,Darius22TomographyNeAT,he2024fluorescencediffractiontomographyusing} have exploited implicit neural fields~\cite{sitzmann2019siren,Mildenhall2020NERF} for regularizing this inversion problem. The idea is that as part of the inversion problem a neural network is trained. This network takes as input a 3D position inside the volume $\ptd$ and outputs its RI $\refin(\ptd)$. As part of the optimization, network weights are adjusted so that the network fits the volumetric structure of the current sample and in a sense, the volume is coded by the network weights. The network capacity, however, is limited and hence it cannot fit noise, but adapt to smooth natural structures. 
%%The approach has been applied to numerous computer vision problems, such as NeRF novel-view synthesis~\cite{Mildenhall2020NERF} and 3D scene reconstruction~\cite{sitzmann2019siren}. It was also successfully applied for diffraction tomography reconstruction by~\cite{Zhou:20,liu2022recoverycontinuous3drefractive,Darius22TomographyNeAT,he2024fluorescencediffractiontomographyusing}. We plan to incorporate these ideas in our system.
%An important adaptation to our problem is to modify   the penalty of such networks so that they only consider the error in the prediction of the transmission matrix rather than error of the 3D reconstruction, since as mentioned above, the transmission matrix is invariant to most of the ambiguities of the actual 3D reconstruction.


\boldstart{Summary of contributions.} Conventional wavefront shaping (WFS) algorithms compute 2D correction patterns that are inherently local, providing correction only over an extremely small  FOV. In contrast, the central goal of this research is to recover a 3D model that enables the prediction and correction of aberrations for every point within the tissue volume. We achieve this by exploiting diffraction tomography. Our approach involves illuminating the tissue from multiple directions with coherent light, measuring the resulting scattered wavefronts, and using them  to reconstruct the 3D RI map of the tissue volume. This 3D model allows us to computationally determine the precise WFS correction required for any point, enabling the subsequent volumetric scanning and imaging of fluorescent targets. A critical advantage of this method is that it measures the propagation  of external coherent light, which is a far more robust and efficient process than relying on feedback from the weak, incoherent fluorescent emission itself. This  decoupling minimizes the required power and significantly reduces the risks of phototoxicity and tissue damage.




 

